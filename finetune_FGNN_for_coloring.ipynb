{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "smooth-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from toolbox import losses\n",
    "from toolbox.losses import coloring_loss, triplet_loss\n",
    "from toolbox import metrics\n",
    "from loaders.loaders import siamese_loader\n",
    "from toolbox.metrics import all_losses_acc, accuracy_linear_assignment\n",
    "from toolbox.utils import check_dir\n",
    "from models import coloring_model, get_siamese_model_test\n",
    "from models import utils\n",
    "from loaders import data_generator\n",
    "importlib.reload(data_generator)\n",
    "from loaders.data_generator import KCOL_Generator, QAP_Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "junior-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_config(model_path):\n",
    "    \"\"\" Get the same device as used for training \"\"\"\n",
    "    config_file = os.path.join(model_path,'config.json')\n",
    "    with open(config_file) as json_file:\n",
    "        config_model = json.load(json_file)\n",
    "    use_cuda = not config_model['cpu'] and torch.cuda.is_available()\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "    return config_model, device\n",
    "\n",
    "def acc_2_error(mean_acc, q_acc):\n",
    "    error = q_acc-mean_acc[:,np.newaxis]\n",
    "    error[:,0] = -error[:,0]\n",
    "    return error\n",
    "\n",
    "def compute_dataset(args,path_dataset,train=True,bs=10):\n",
    "    num_batches = math.ceil(args['num_examples_val']/bs)\n",
    "    if train:\n",
    "        gene = KCOL_Generator('train', args, path_dataset)\n",
    "    else:\n",
    "        gene = KCOL_Generator('test', args, path_dataset)\n",
    "    gene.load_dataset()\n",
    "    loader = siamese_loader(gene, bs, gene.constant_n_vertices)\n",
    "    return loader\n",
    "\n",
    "def compute_quant(all_acc,quant_low=0.1,quant_up=0.9):\n",
    "    mean_acc = np.mean(all_acc,1)\n",
    "    num = len(mean_acc)\n",
    "    q_acc = np.zeros((num,2))\n",
    "    for i in range(num):\n",
    "        q_acc[i,:] = np.quantile(all_acc[i,:],[quant_up, quant_low])\n",
    "    return mean_acc, q_acc\n",
    "\n",
    "def train_epoch(model, embed_model, train_loader):\n",
    "    loss_fn = coloring_loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    model.train()\n",
    "    cum_loss = 0\n",
    "    for idx, (graph,tgt) in enumerate(train_loader):\n",
    "        graph['input'] = graph['input'].to(device)\n",
    "        embed = embed_model.node_embedder(graph)['ne/suffix']\n",
    "        embed = torch.permute(embed,(0,2,1))\n",
    "        \n",
    "        tgt = tgt['input'].to(device)\n",
    "        \n",
    "        out = model(embed)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(graph['input'], out, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        cum_loss += loss.item()\n",
    "    return cum_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    cum_loss = 0\n",
    "    for idx, (graph, tgt) in (enumerate(valid_loader)):\n",
    "        graph['input'] = graph['input'].to(device)\n",
    "        embed = embed_model.node_embedder(graph)['ne/suffix']\n",
    "        embed = torch.permute(embed,(0,2,1))\n",
    "        \n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        out = model(embed)\n",
    "        \n",
    "        loss = loss_fn(out, tgt)\n",
    "        cum_loss += loss.item()\n",
    "    return cum_loss / len(val_loader) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-capital",
   "metadata": {},
   "source": [
    "## Loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "309bc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd = \"/\".join(cwd.split(\"/\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "answering-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Siamese_Node_Exp(\n",
       "  (node_embedder): Network(\n",
       "    (ne_bm_in): GraphNorm()\n",
       "    (ne_bm_block1_mlp3): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(2, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_cat1): Concat()\n",
       "    (ne_bm_block2_mlp1): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_block2_mlp2): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_block2_mult): Matmul()\n",
       "    (ne_bm_block2_cat): Concat()\n",
       "    (ne_bm_block2_mlp3): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(130, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_cat2): Concat()\n",
       "    (ne_bm_block3_mlp1): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_block3_mlp2): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_block3_mult): Matmul()\n",
       "    (ne_bm_block3_cat): Concat()\n",
       "    (ne_bm_block3_mlp3): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(130, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_cat3): Concat()\n",
       "    (ne_bm_block4_mlp1): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_block4_mlp2): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_bm_block4_mult): Matmul()\n",
       "    (ne_bm_block4_cat): Concat()\n",
       "    (ne_bm_block4_mlp3): MlpBlock_Real(\n",
       "      (convs): ModuleList(\n",
       "        (0): Conv2d(130, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1-2): 2 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (gn): GraphNorm()\n",
       "    )\n",
       "    (ne_suffix): ColumnMaxPooling()\n",
       "  )\n",
       "  (loss): triplet_loss(\n",
       "    (loss): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = cwd+'/experiments-gnn/qap/expe_new/node_embedding_rec_Regular_150_0.05/05-15-23-16-14'\n",
    "config_model, device = get_device_config(model_path)\n",
    "embed_model = get_siamese_model_test(config_model[\"data\"][\"test\"][\"path_model\"])\n",
    "embed_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-vocabulary",
   "metadata": {},
   "source": [
    "## Generating data and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6fc6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model[\"data\"][\"test\"][\"k\"] = 5\n",
    "config_model[\"data\"][\"test\"][\"num_examples_train\"] = 2000\n",
    "config_model[\"data\"][\"test\"][\"num_examples_val\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-belarus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset at /home/mdepres/experiments-gnn/kcol/data/Color_ErdosRenyi_2000_150_1.0_0.05/train.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████▍                       | 1372/2000 [04:14<01:55,  5.42it/s]"
     ]
    }
   ],
   "source": [
    "args = config_model[\"data\"][\"test\"]\n",
    "train_loader = compute_dataset(args, cwd+'/experiments-gnn/kcol/data')\n",
    "valid_loader = compute_dataset(args, cwd+'/experiments-gnn/kcol/data', train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9acc7f",
   "metadata": {},
   "source": [
    "## Training a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43806ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 5) (1500, 64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1500, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m tgt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresize(tgt, (tgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mtgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],tgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(tgt\u001b[38;5;241m.\u001b[39mshape, embed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:849\u001b[0m, in \u001b[0;36mBaseSGDClassifier.partial_fit\u001b[0;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit. In order to use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m weights,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight)\n\u001b[1;32m    847\u001b[0m         )\n\u001b[0;32m--> 849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:579\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_partial_fit\u001b[39m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    566\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     intercept_init,\n\u001b[1;32m    577\u001b[0m ):\n\u001b[1;32m    578\u001b[0m     first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 579\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    591\u001b[0m     _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:1143\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1143\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1204\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1500, 5) instead."
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log_loss', warm_start=True)\n",
    "\n",
    "for idx, (graph,tgt) in enumerate(train_loader):\n",
    "    graph['input'] = graph['input'].to(device)\n",
    "    embed = embed_model.node_embedder(graph)['ne/suffix']\n",
    "    \n",
    "    embed = embed.cpu().detach().numpy()\n",
    "    embed = np.swapaxes(embed,1,2)\n",
    "    embed = np.resize(embed, (embed.shape[0]*embed.shape[1],embed.shape[-1]))\n",
    "    tgt = tgt['input']\n",
    "    tgt = np.resize(tgt, (tgt.shape[0]*tgt.shape[1],tgt.shape[-1]))\n",
    "    \n",
    "    print(tgt.shape, embed.shape)\n",
    "    clf.partial_fit(embed, tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-virus",
   "metadata": {},
   "source": [
    "## Training the coloring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = coloring_model.ColoringModel(args['n_vertices'],embed_dim=64, k=args[\"k\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-tampa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, embed_model, train_loader)\n",
    "    end_time = time.time()\n",
    "    val_loss = evaluate(model, valid_loader)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
