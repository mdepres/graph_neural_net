---
problem: mbs # PB_DIR = experiments-gnn/$problem
name: experiment_mbs # results will be stored in PB_DIR/$name
cpu: No
k: 5
#root_dir: 'experiments-gnn' # not used...
#test_enabled: Yes
#use_dgl: No
#path_dataset: data # Path where datasets are stored, default data/

data:
    train: # Train/Val data generation parameters
        num_examples_train: 2000
        num_examples_val: 100
        n_vertices: 50
        sparsify: None #Only works for not fgnns. Put to None if you don't want sparsifying
        generative_model: Regular # so far ErdosRenyi, Regular or BarabasiAlbert
        noise_model: ErdosRenyi
        edge_density: 0.2 #0.015 #0.025
        connection_density: 0.05
        vertex_proba: 1. # Parameter of the binomial distribution of vertices
        noise: 0.2 #0.3 #0.32 #0.2 #0.2 0.4 0.6 0.8 0.9
            
    test: #Test data generation parameters not used yet...
        num_examples_test: 300
        n_vertices: 50
        sparsify: None #Only works for not fgnns. Put to None if you don't want sparsifying
        #custom: No #If No, keeps the data_generation from train, just a failsafe so people consciously have to activate custom test
        generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
        noise_model: ErdosRenyi
        edge_density: 0.5
        vertex_proba: 1. # Parameter of the binomial distribution of vertices
        noise: 0.05
        path_model: '/home/mlelarge/experiments-gnn/qap/norm_dense/node_embedding_block_ErdosRenyi_100_0.5/12-05-22-17-34/qap_norm_dense/2gf519dg/checkpoints/epoch=9-step=6250.ckpt'


train: # Training parameters
    epochs: 10
    batch_size:  32 #10 #8 #32 #16 #64
    lr: !!float 1e-3 #1e-3
    scheduler_step: 3
    scheduler_decay: 0.5
    lr_stop: !!float 1e-5
    log_freq: 50
    anew: Yes
    start_model: '/home/mlelarge/experiments-gnn/qap/qap_res/gatedgcn_8_ErdosRenyi_64_0.09375/02-11-22-20-55/model_best.pth.tar' #'/home/mlelarge/experiments-gnn/qap/qap_res/fgnn_4_ErdosRenyi_64_0.09375/02-11-22-09-31/model_best.pth.tar'

arch: # Architecture and model
    original_features_num: 2 # 2 for fgnn 1 for mgnn
    node_emb: 
        type: node_embedding_rec
        block_init: block_emb
        block_inside: block
        num_blocks: 4
        in_features: 64
        out_features: 64
        depth_of_mlp: 3
        num_heads: 16
    
    #arch_gnn: fgnn #fgnn, gcn, gatedgcn
    #arch_load: siamese #siamese or simple(to be done)
    #embedding: node #node or edge, rs_node
    #num_blocks: 4 #4
    
    #dim_features: 64 #64
    #depth_of_mlp: 3 
    #input_embed: No # No

observers:
    wandb: Yes

